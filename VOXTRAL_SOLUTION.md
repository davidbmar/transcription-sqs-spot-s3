# Real Voxtral Working Solution

## üéâ Status: WORKING ‚úÖ

This document describes the complete working solution for Real Voxtral (mistralai/Voxtral-Mini-3B-2507) transcription.

## üîß Problem & Solution

### Original Problem
- **Error**: `shape mismatch: value tensor of shape [375, 3072] cannot be broadcast to indexing result of shape [0, 3072]`
- **Root Cause**: Missing audio token placeholders in input sequence
- **Version Issue**: Requires transformers 4.54.0.dev0 (bleeding edge)

### Working Solution
**Key Innovation**: Dynamic audio token calculation with placeholder insertion

```python
# Calculate required audio tokens
num_audio_tokens = audio_features.time_steps // 8  # 375 for 30-second audio

# Create input sequence with placeholders
input_sequence = [BOS] + [AUDIO_TOKEN]*num_audio_tokens + transcribe_tokens + [EOS]
```

## üìä Performance Metrics

| Metric | Result |
|--------|--------|
| **Model Loading** | 40 seconds (with S3 cache) |
| **Processing Speed** | 1.18x real-time for 30-second audio |
| **Max Input Length** | ~30 seconds per request |
| **Model Size** | 4.7B parameters |
| **GPU Memory** | ~8.8GB VRAM required |

## üèóÔ∏è Architecture

### Input Format
```
Sequence: [BOS] + [AUDIO]*N + "Transcribe this audio." + [EOS]
Where:
  - N = audio_features.time_steps // 8
  - AUDIO_TOKEN_ID = 24 (from vocabulary)
  - BOS_TOKEN_ID = 1
  - EOS_TOKEN_ID = 2
```

### Processing Pipeline
1. **Audio Features**: Extract using WhisperFeatureExtractor (16kHz, mono)
2. **Token Calculation**: Determine number of audio placeholders needed
3. **Sequence Creation**: Build input with dynamic audio tokens
4. **Model Generation**: Process with VoxtralForConditionalGeneration
5. **Decoding**: Extract only new tokens, skip input prompt

## üöÄ Deployment

### Requirements
- **GPU**: NVIDIA T4 or better (14GB VRAM minimum)
- **Dependencies**: transformers>=4.54.0.dev0 (from GitHub)
- **Docker**: 25.3GB image with CUDA 11.8 support

### Steps
1. Run `step-405-voxtral-setup-model-cache.sh` (cache model to S3)
2. Run `step-420-voxtral-launch-gpu-instances.sh` (launch workers)
3. Run `step-430-voxtral-test-transcription.sh` (verify working)

## ‚ö†Ô∏è Limitations

### Input Length
- **Maximum**: ~30 seconds per request
- **Reason**: Model has fixed maximum context length
- **Workaround**: Implement chunking for longer audio

### Version Dependency
- **Required**: transformers 4.54.0.dev0 (development version)
- **Risk**: Potential instability, changes in future versions
- **Alternative**: Wait for stable release with Voxtral support

### Model Maturity
- **Age**: 18 days old (very new)
- **Documentation**: Limited, architecture undocumented
- **Support**: Community-driven fixes

## üÜö Comparison

### vs Whisper-large-v3
| Feature | Real Voxtral | Whisper-large-v3 |
|---------|--------------|-------------------|
| **Max Length** | 30 seconds | Hours |
| **Setup Complexity** | High (bleeding edge) | Low (stable) |
| **Performance** | 1.18x real-time | 2-5x real-time |
| **Quality** | Excellent | Excellent |
| **Stability** | New/Unstable | Mature/Stable |

### Production Recommendation
- **Short Audio (<30s)**: Real Voxtral
- **Long Audio (>30s)**: Whisper-large-v3
- **Enterprise**: Whisper-large-v3 for reliability

## üî¨ Technical Details

### Audio Token Calculation
```python
def calculate_audio_tokens_needed(audio_features):
    batch_size, n_features, time_steps = audio_features.shape
    # Empirical ratio: 375 tokens for 3000 time steps
    num_audio_tokens = max(1, time_steps // 8)
    return num_audio_tokens
```

### Input Sequence Creation
```python
# Get special tokens
vocab = processor.tokenizer.get_vocab()
audio_token_id = vocab.get('[AUDIO]', 24)
bos_token_id = processor.tokenizer.bos_token_id or 1
eos_token_id = processor.tokenizer.eos_token_id or 2

# Create sequence
transcribe_tokens = processor.tokenizer.encode('Transcribe this audio.', add_special_tokens=False)
input_sequence = ([bos_token_id] + 
                 [audio_token_id] * num_audio_tokens + 
                 transcribe_tokens + 
                 [eos_token_id])
```

## üìù Example Usage

### API Request
```bash
curl -X POST \
  -F "file=@audio.mp3" \
  http://worker-ip:8000/transcribe
```

### Response
```json
{
  "filename": "audio.mp3",
  "text": "Transcribed text here...",
  "model": "mistralai/Voxtral-Mini-3B-2507",
  "processing_time": 25.5,
  "audio_duration": 30.0,
  "real_time_factor": 1.18,
  "method": "dynamic_audio_tokens_v1",
  "audio_tokens_used": 375
}
```

## üêõ Troubleshooting

### Common Issues
1. **Shape mismatch error**: Check transformers version (need dev version)
2. **Model not loading**: Verify GPU memory (need 14GB+)
3. **Import error**: Install transformers from GitHub source

### Debug Commands
```bash
# Check transformers version
docker exec container python3 -c "import transformers; print(transformers.__version__)"

# Test audio token calculation
docker exec container python3 -c "from transformers import AutoProcessor; processor = AutoProcessor.from_pretrained('mistralai/Voxtral-Mini-3B-2507'); print('‚úÖ Processor loaded')"

# Monitor GPU usage
nvidia-smi
```

## üìö References

- **Model**: [mistralai/Voxtral-Mini-3B-2507](https://huggingface.co/mistralai/Voxtral-Mini-3B-2507)
- **Transformers**: [GitHub](https://github.com/huggingface/transformers)
- **Issue Tracking**: Document shape mismatch bug for HuggingFace team

---

**Last Updated**: 2025-07-20  
**Status**: Production ready for short audio (<30s)  
**Version**: dynamic_audio_tokens_v1